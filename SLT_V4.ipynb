{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\ssn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ssn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from imbalanced-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ssn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from imbalanced-learn) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\ssn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ssn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ssn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from imbalanced-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\SSN\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import mediapipe as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique classes: 2000\n"
     ]
    }
   ],
   "source": [
    "# Load your CSV file containing video labels and IDs\n",
    "csv_path = 'features_df.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = df['gloss'].nunique()\n",
    "\n",
    "print(\"Number of unique classes:\", unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mediapipe\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to extract keypoints from a frame\n",
    "\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = model.process(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks,\n",
    "                              mp_holistic.FACEMESH_CONTOURS)  # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks,\n",
    "                              mp_holistic.POSE_CONNECTIONS)  # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks,\n",
    "                              mp_holistic.HAND_CONNECTIONS)  # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks,\n",
    "                              mp_holistic.HAND_CONNECTIONS)  # Draw right hand connections\n",
    "\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
    "                              mp_drawing.DrawingSpec(\n",
    "                                  color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                              mp_drawing.DrawingSpec(\n",
    "                                  color=(80, 256, 121), thickness=1, circle_radius=1)\n",
    "                              )\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(\n",
    "                                  color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                              mp_drawing.DrawingSpec(\n",
    "                                  color=(80, 44, 121), thickness=2, circle_radius=2)\n",
    "                              )\n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(\n",
    "                                  color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                              mp_drawing.DrawingSpec(\n",
    "                                  color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "                              )\n",
    "    # Draw right hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(\n",
    "                                  color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                              mp_drawing.DrawingSpec(\n",
    "                                  color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                              )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Video: book\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Set paths\n",
    "csv_path = 'features_df.csv'\n",
    "videos_folder = 'videos'\n",
    "\n",
    "\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['SLT']\n",
    "collection = db['frames']\n",
    "\n",
    "\n",
    "\n",
    "# Initialize Mediapipe\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to extract keypoints from a frame\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = model.process(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return results\n",
    "\n",
    "# Function to preprocess a video\n",
    "def preprocess_video(video_path, target_size=(64, 64)):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Initialize Mediapipe model\n",
    "    holistic = mp_holistic.Holistic()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Extract keypoints using Mediapipe\n",
    "        results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "        # Draw styled landmarks on the frame\n",
    "        draw_styled_landmarks(frame, results)\n",
    "\n",
    "        # Resize frame to the target size\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frames.append(frame)\n",
    "    \n",
    "    frames = [cv2.resize(frame, target_size) for frame in frames]\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "# Lists to store preprocessed data and labels\n",
    "preprocessed_data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "start = 0\n",
    "# Iterate through rows of the DataFrame\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if start >= index:\n",
    "        video_filename = str(row['video_id']) + '.mp4'\n",
    "        sign_label = row['gloss']\n",
    "        video_path = os.path.join(videos_folder, video_filename)\n",
    "\n",
    "        # Check if the video file exists\n",
    "        if os.path.exists(video_path):\n",
    "            frames = preprocess_video(video_path)\n",
    "            preprocessed_data.append(frames)\n",
    "            data_entry = {\n",
    "            'frames': frames.tolist(),  # Convert NumPy array to Python list\n",
    "            'label': sign_label\n",
    "            }\n",
    "            collection.insert_one(data_entry)\n",
    "            labels.append(sign_label)\n",
    "            print(\"Processed Video:\",sign_label)\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (63,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\SLT\\SLT_V4.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SLT/SLT_V4.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(data), np\u001b[39m.\u001b[39marray(labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SLT/SLT_V4.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Close the MongoDB connection\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SLT/SLT_V4.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SLT/SLT_V4.ipynb#X20sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SLT/SLT_V4.ipynb#X20sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Retrieve data and labels\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SLT/SLT_V4.ipynb#X20sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m X, y \u001b[39m=\u001b[39m retrieve_data_labels()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SLT/SLT_V4.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Print the shape of the data and labels\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SLT/SLT_V4.ipynb#X20sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mData shape:\u001b[39m\u001b[39m\"\u001b[39m, X\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;32md:\\SLT\\SLT_V4.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SLT/SLT_V4.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     data\u001b[39m.\u001b[39mappend(frames)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SLT/SLT_V4.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     labels\u001b[39m.\u001b[39mappend(label)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SLT/SLT_V4.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49marray(data), np\u001b[39m.\u001b[39marray(labels)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (63,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Set MongoDB connection details\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['SLT']\n",
    "collection = db['frames']\n",
    "\n",
    "# Retrieve data and labels from MongoDB\n",
    "def retrieve_data_labels():\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    cursor = collection.find()\n",
    "    for document in cursor:\n",
    "        frames = np.array(document['frames'])\n",
    "        label = document['label']\n",
    "        data.append(frames)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Close the MongoDB connection\n",
    "\n",
    "\n",
    "# Retrieve data and labels\n",
    "X, y = retrieve_data_labels()\n",
    "\n",
    "# Print the shape of the data and labels\n",
    "print(\"Data shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)\n",
    "\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
